{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzONAJEoMP6+JoTB1gYCoT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveengrb/nlp/blob/main/NLTK_PreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhRTgBgRIoS3",
        "outputId": "bcd8bd7a-b67b-402b-a4bd-c45896246a61"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qKflGfgo4s_4"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence and Word Tokenization"
      ],
      "metadata": {
        "id": "Uoceqzn6ISZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_TEXT='''Stop words are the words in a stop list (or stoplist or negative dictionary) which are filtered out (i.e. stopped) before or after processing of natural language data (text) because they are insignificant.[1] There is no single universal list of stop words used by all natural language processing tools, nor any agreed upon rules for identifying stop words, and indeed not all tools even use such a list. Therefore, any group of words can be chosen as the stop words for a given purpose. The \"general trend in [information retrieval] systems over time has been from standard use of quite large stop lists (200–300 terms) to very small stop lists (7–12 terms) to no stop list whatsoever\".[2]'''\n",
        "sent_tokenized_words=sent_tokenize(SAMPLE_TEXT)\n",
        "tokenized_words=word_tokenize(SAMPLE_TEXT)"
      ],
      "metadata": {
        "id": "OdBPtNyzIV8x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sent_tokenized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LjROwnBI8t3",
        "outputId": "b6ef54bf-bae0-430d-b6d7-5c9ffe8b9ec6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Stop words are the words in a stop list (or stoplist or negative dictionary) which are filtered out (i.e.', 'stopped) before or after processing of natural language data (text) because they are insignificant.', '[1] There is no single universal list of stop words used by all natural language processing tools, nor any agreed upon rules for identifying stop words, and indeed not all tools even use such a list.', 'Therefore, any group of words can be chosen as the stop words for a given purpose.', 'The \"general trend in [information retrieval] systems over time has been from standard use of quite large stop lists (200–300 terms) to very small stop lists (7–12 terms) to no stop list whatsoever\".', '[2]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS4U3ISPJIHC",
        "outputId": "4a3f2c61-3ff9-46f0-8d4f-d70ca01af3f5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Stop', 'words', 'are', 'the', 'words', 'in', 'a', 'stop', 'list', '(', 'or', 'stoplist', 'or', 'negative', 'dictionary', ')', 'which', 'are', 'filtered', 'out', '(', 'i.e', '.', 'stopped', ')', 'before', 'or', 'after', 'processing', 'of', 'natural', 'language', 'data', '(', 'text', ')', 'because', 'they', 'are', 'insignificant', '.', '[', '1', ']', 'There', 'is', 'no', 'single', 'universal', 'list', 'of', 'stop', 'words', 'used', 'by', 'all', 'natural', 'language', 'processing', 'tools', ',', 'nor', 'any', 'agreed', 'upon', 'rules', 'for', 'identifying', 'stop', 'words', ',', 'and', 'indeed', 'not', 'all', 'tools', 'even', 'use', 'such', 'a', 'list', '.', 'Therefore', ',', 'any', 'group', 'of', 'words', 'can', 'be', 'chosen', 'as', 'the', 'stop', 'words', 'for', 'a', 'given', 'purpose', '.', 'The', '``', 'general', 'trend', 'in', '[', 'information', 'retrieval', ']', 'systems', 'over', 'time', 'has', 'been', 'from', 'standard', 'use', 'of', 'quite', 'large', 'stop', 'lists', '(', '200–300', 'terms', ')', 'to', 'very', 'small', 'stop', 'lists', '(', '7–12', 'terms', ')', 'to', 'no', 'stop', 'list', 'whatsoever', \"''\", '.', '[', '2', ']']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop words: Are Natural words which have a very littile meaning. For Example: a, the, etc.\n",
        "These words might take a lot of space in database. They can be removed by storing a list of stop words. In our import statements, we have imported stopwords from nltk corpus."
      ],
      "metadata": {
        "id": "N64lpE2uKQVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=set(stopwords.words('english'))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz3GLcEFJOyp",
        "outputId": "09ec5f74-f5dd-42d4-d011-3d979cc3bce0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'him', 'do', 'between', 'now', \"shan't\", 'wasn', \"won't\", \"don't\", \"haven't\", 'some', 'doing', \"mustn't\", \"hasn't\", 'themselves', 'above', 'at', 'being', 'ma', 'yourselves', 'for', 'weren', 'don', \"needn't\", 'both', 'should', 'who', \"hadn't\", 're', 'mustn', 'or', 'not', 'be', 'just', 'other', 'won', 'he', 'how', \"doesn't\", 'you', 'which', 'having', 'your', 'before', 'is', \"you'll\", 'herself', 'shan', 'few', 'these', 'what', 'her', 'she', 'under', 'yourself', 'then', 'did', 'whom', 've', 'hasn', 'them', 'm', 'more', 'we', 'while', 'yours', 'all', 'hers', \"isn't\", 'to', 'than', 'nor', 'by', 'during', 'as', 'are', 'with', 'mightn', 'after', 'i', 'this', \"that'll\", 'through', 'own', \"weren't\", 'wouldn', 'when', 'so', \"didn't\", 'but', 'over', 'those', 'a', 'they', 'of', 'same', \"you're\", 'if', \"couldn't\", 'couldn', 'hadn', 'once', 's', 'where', 'there', 'out', 'will', 'had', 'each', 'our', 'no', 'didn', 'isn', 'ours', 'its', \"aren't\", 'their', 'his', 'were', 'll', 'needn', \"shouldn't\", 't', 'again', 'very', 'down', 'only', 'about', 'ourselves', 'from', 'theirs', 'himself', 'an', 'most', 'that', 'ain', 'haven', 'itself', 'aren', 'shouldn', 'has', \"it's\", \"should've\", 'was', 'doesn', \"wasn't\", 'any', \"wouldn't\", 'off', 'up', 'myself', \"mightn't\", 'against', 'why', \"you'd\", 'does', 'until', 'd', 'me', 'further', 'y', 'in', 'my', 'o', 'on', 'such', 'too', 'below', \"she's\", 'have', 'and', 'into', \"you've\", 'because', 'here', 'the', 'am', 'it', 'can', 'been'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence=[ w for w in tokenized_words if not w in stop_words ]"
      ],
      "metadata": {
        "id": "Q006p0FpLYUu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above way can be written as below"
      ],
      "metadata": {
        "id": "6C_uoomPMgz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence=[]\n",
        "for w in tokenized_words:\n",
        "  if w not in stop_words:\n",
        "    filtered_sentence.append(w)"
      ],
      "metadata": {
        "id": "yeVbF5-vMeJq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LlPie_EM3Rt",
        "outputId": "34c8154e-106c-4f73-8062-4a5131f03c34"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Stop', 'words', 'words', 'stop', 'list', '(', 'stoplist', 'negative', 'dictionary', ')', 'filtered', '(', 'i.e', '.', 'stopped', ')', 'processing', 'natural', 'language', 'data', '(', 'text', ')', 'insignificant', '.', '[', '1', ']', 'There', 'single', 'universal', 'list', 'stop', 'words', 'used', 'natural', 'language', 'processing', 'tools', ',', 'agreed', 'upon', 'rules', 'identifying', 'stop', 'words', ',', 'indeed', 'tools', 'even', 'use', 'list', '.', 'Therefore', ',', 'group', 'words', 'chosen', 'stop', 'words', 'given', 'purpose', '.', 'The', '``', 'general', 'trend', '[', 'information', 'retrieval', ']', 'systems', 'time', 'standard', 'use', 'quite', 'large', 'stop', 'lists', '(', '200–300', 'terms', ')', 'small', 'stop', 'lists', '(', '7–12', 'terms', ')', 'stop', 'list', 'whatsoever', \"''\", '.', '[', '2', ']']\n"
          ]
        }
      ]
    }
  ]
}